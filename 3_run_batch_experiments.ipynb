{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Experiments: Adaptive Integrated Grad-CAM\n",
    "# =================================================\n",
    "\n",
    "This notebook runs comprehensive experiments comparing:\n",
    "- **Adaptive Method** (ours) - dynamically allocates 10-100 steps\n",
    "- **Fixed-25** - always uses 25 integration steps\n",
    "- **Fixed-50** - always uses 50 integration steps  \n",
    "- **Fixed-100** - always uses 100 integration steps\n",
    "\n",
    "## Metrics Collected:\n",
    "1. Deletion AUC (lower is better)\n",
    "2. Insertion AUC (higher is better)\n",
    "3. Average Drop (lower is better)\n",
    "4. Computation time (seconds)\n",
    "5. Steps allocated (for adaptive)\n",
    "6. Image complexity metrics\n",
    "\n",
    "## Expected Runtime:\n",
    "~5 minutes for 20 images on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from adaptive_integrated_gradcam import AdaptiveIntegratedGradCAM, BaselineIntegratedGradCAM\n",
    "from evaluation_metrics import AttributionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = 'medical_images'\n",
    "NUM_IMAGES = 20\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "# Adaptive method parameters\n",
    "MIN_STEPS = 10\n",
    "MAX_STEPS = 100\n",
    "VARIANCE_THRESHOLD = 0.1\n",
    "CONVERGENCE_THRESHOLD = 0.05\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Number of images: {NUM_IMAGES}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Adaptive: min={MIN_STEPS}, max={MAX_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BATCH EXPERIMENTS: Adaptive Integrated Grad-CAM\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDevice: {device}\")\n",
    "\n",
    "if device == 'cpu':\n",
    "    print(\"⚠ Warning: Running on CPU. This will be slow.\")\n",
    "    print(\"  Consider using GPU for faster experiments.\")\n",
    "else:\n",
    "    print(f\"✓ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path(OUTPUT_DIR)\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "print(f\"\\nResults directory: {results_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(\"\\nLoading model...\")\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "target_layer = model.layer4[-1]\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(\"✓ Model loaded: ResNet-50\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Target layer: layer4[-1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize methods\n",
    "print(\"\\nInitializing attribution methods...\")\n",
    "\n",
    "methods_dict = {\n",
    "    'adaptive': {\n",
    "        'method': AdaptiveIntegratedGradCAM(\n",
    "            model, target_layer,\n",
    "            min_steps=MIN_STEPS,\n",
    "            max_steps=MAX_STEPS,\n",
    "            variance_threshold=VARIANCE_THRESHOLD,\n",
    "            convergence_threshold=CONVERGENCE_THRESHOLD\n",
    "        ),\n",
    "        'use_adaptive': True\n",
    "    },\n",
    "    'fixed_25': {\n",
    "        'method': BaselineIntegratedGradCAM(model, target_layer, num_steps=25),\n",
    "        'num_steps': 25\n",
    "    },\n",
    "    'fixed_50': {\n",
    "        'method': BaselineIntegratedGradCAM(model, target_layer, num_steps=50),\n",
    "        'num_steps': 50\n",
    "    },\n",
    "    'fixed_100': {\n",
    "        'method': BaselineIntegratedGradCAM(model, target_layer, num_steps=100),\n",
    "        'num_steps': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"✓ Methods initialized:\")\n",
    "for name in methods_dict.keys():\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = AttributionEvaluator(model, device)\n",
    "print(\"✓ Evaluator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def load_and_preprocess_image(image_path, device='cpu'):\n",
    "    \"\"\"Load and preprocess image for ResNet.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        return image_tensor, image, True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {image_path}: {e}\")\n",
    "        return None, None, False\n",
    "\n",
    "def calculate_image_complexity(image_pil):\n",
    "    \"\"\"Calculate image complexity metrics.\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    img_array = np.array(image_pil)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    hist, _ = np.histogram(img_array.flatten(), bins=256, range=(0, 255), density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    entropy = -np.sum(hist * np.log2(hist))\n",
    "    \n",
    "    # Calculate edge density\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    # Calculate variance\n",
    "    variance = np.var(img_array)\n",
    "    \n",
    "    return {\n",
    "        'entropy': entropy,\n",
    "        'edge_density': edge_density,\n",
    "        'variance': variance\n",
    "    }\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image paths\n",
    "data_dir = Path(DATA_DIR)\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "image_paths = []\n",
    "\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(list(data_dir.glob(f'*{ext}')))\n",
    "    image_paths.extend(list(data_dir.glob(f'*{ext.upper()}')))\n",
    "\n",
    "image_paths = sorted(set(image_paths))[:NUM_IMAGES]\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(f\"\\n✗ No images found in {data_dir}\")\n",
    "    print(\"Please run: 2_create_sample_dataset.ipynb\")\n",
    "else:\n",
    "    print(f\"\\n✓ Found {len(image_paths)} images\")\n",
    "    print(\"\\nSample images:\")\n",
    "    for i, path in enumerate(image_paths[:5]):\n",
    "        print(f\"  {i+1}. {path.name}\")\n",
    "    if len(image_paths) > 5:\n",
    "        print(f\"  ... and {len(image_paths) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nProcessing {len(image_paths)} images with 4 methods...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, image_path in enumerate(tqdm(image_paths, desc=\"Processing images\")):\n",
    "    # Load image\n",
    "    image_tensor, image_pil, success = load_and_preprocess_image(image_path, device)\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        confidence = torch.softmax(output, dim=1)[0, pred_class].item()\n",
    "    \n",
    "    # Calculate complexity\n",
    "    complexity_metrics = calculate_image_complexity(image_pil)\n",
    "    \n",
    "    # Initialize result\n",
    "    result = {\n",
    "        'image_path': str(image_path),\n",
    "        'image_name': Path(image_path).name,\n",
    "        'pred_class': pred_class,\n",
    "        'confidence': confidence,\n",
    "        **complexity_metrics\n",
    "    }\n",
    "    \n",
    "    # Run each method\n",
    "    for method_name, method_config in methods_dict.items():\n",
    "        method_obj = method_config['method']\n",
    "        use_adaptive = method_config.get('use_adaptive', False)\n",
    "        \n",
    "        try:\n",
    "            # Generate CAM and measure time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            if use_adaptive:\n",
    "                cam, steps_used = method_obj.generate_cam(\n",
    "                    image_tensor, pred_class, use_adaptive=True\n",
    "                )\n",
    "            else:\n",
    "                cam = method_obj.generate_cam(image_tensor, pred_class)\n",
    "                steps_used = method_config.get('num_steps', 0)\n",
    "            \n",
    "            generation_time = time.time() - start_time\n",
    "            \n",
    "            # Compute metrics\n",
    "            _, deletion_auc = evaluator.deletion_metric(\n",
    "                image_tensor, cam, pred_class, steps=10\n",
    "            )\n",
    "            \n",
    "            _, insertion_auc = evaluator.insertion_metric(\n",
    "                image_tensor, cam, pred_class, steps=10\n",
    "            )\n",
    "            \n",
    "            avg_drop = evaluator.average_drop(\n",
    "                image_tensor, cam, pred_class, percentile=0.1\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            result[f'{method_name}_time'] = generation_time\n",
    "            result[f'{method_name}_deletion_auc'] = deletion_auc\n",
    "            result[f'{method_name}_insertion_auc'] = insertion_auc\n",
    "            result[f'{method_name}_avg_drop'] = avg_drop\n",
    "            result[f'{method_name}_steps'] = steps_used\n",
    "            \n",
    "            # For adaptive, store additional info\n",
    "            if use_adaptive and hasattr(method_obj, 'step_allocation_history'):\n",
    "                if len(method_obj.step_allocation_history) > 0:\n",
    "                    history = method_obj.step_allocation_history[-1]\n",
    "                    result[f'{method_name}_gradient_variance'] = history.get('gradient_variance', 0)\n",
    "                    result[f'{method_name}_attribution_change'] = history.get('attribution_change', 0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Error with {method_name} on {image_path.name}: {e}\")\n",
    "            result[f'{method_name}_time'] = np.nan\n",
    "            result[f'{method_name}_deletion_auc'] = np.nan\n",
    "            result[f'{method_name}_insertion_auc'] = np.nan\n",
    "            result[f'{method_name}_avg_drop'] = np.nan\n",
    "            result[f'{method_name}_steps'] = np.nan\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "print(\"\\n✓ Experiments complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = results_dir / 'experiment_results.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✓ Saved results to: {csv_path}\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"  - {df.shape[0]} images processed\")\n",
    "print(f\"  - {df.shape[1]} features per image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of results:\")\n",
    "display_cols = ['image_name', 'confidence', 'adaptive_steps', 'adaptive_time', \n",
    "                'adaptive_deletion_auc', 'fixed_100_time']\n",
    "df[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "summary = {}\n",
    "\n",
    "for method in ['adaptive', 'fixed_25', 'fixed_50', 'fixed_100']:\n",
    "    summary[method] = {\n",
    "        'mean_deletion_auc': df[f'{method}_deletion_auc'].mean(),\n",
    "        'std_deletion_auc': df[f'{method}_deletion_auc'].std(),\n",
    "        'mean_insertion_auc': df[f'{method}_insertion_auc'].mean(),\n",
    "        'std_insertion_auc': df[f'{method}_insertion_auc'].std(),\n",
    "        'mean_avg_drop': df[f'{method}_avg_drop'].mean(),\n",
    "        'std_avg_drop': df[f'{method}_avg_drop'].std(),\n",
    "        'mean_time': df[f'{method}_time'].mean(),\n",
    "        'std_time': df[f'{method}_time'].std(),\n",
    "        'mean_steps': df[f'{method}_steps'].mean() if f'{method}_steps' in df.columns else None,\n",
    "        'std_steps': df[f'{method}_steps'].std() if f'{method}_steps' in df.columns else None,\n",
    "    }\n",
    "\n",
    "# Save summary\n",
    "summary_path = results_dir / 'summary_statistics.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"✓ Saved summary to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Method': ['Adaptive', 'Fixed-25', 'Fixed-50', 'Fixed-100'],\n",
    "    'Del-AUC ↓': [\n",
    "        f\"{summary['adaptive']['mean_deletion_auc']:.4f}±{summary['adaptive']['std_deletion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_25']['mean_deletion_auc']:.4f}±{summary['fixed_25']['std_deletion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_50']['mean_deletion_auc']:.4f}±{summary['fixed_50']['std_deletion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_100']['mean_deletion_auc']:.4f}±{summary['fixed_100']['std_deletion_auc']:.4f}\",\n",
    "    ],\n",
    "    'Ins-AUC ↑': [\n",
    "        f\"{summary['adaptive']['mean_insertion_auc']:.4f}±{summary['adaptive']['std_insertion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_25']['mean_insertion_auc']:.4f}±{summary['fixed_25']['std_insertion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_50']['mean_insertion_auc']:.4f}±{summary['fixed_50']['std_insertion_auc']:.4f}\",\n",
    "        f\"{summary['fixed_100']['mean_insertion_auc']:.4f}±{summary['fixed_100']['std_insertion_auc']:.4f}\",\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        f\"{summary['adaptive']['mean_time']:.3f}±{summary['adaptive']['std_time']:.3f}\",\n",
    "        f\"{summary['fixed_25']['mean_time']:.3f}±{summary['fixed_25']['std_time']:.3f}\",\n",
    "        f\"{summary['fixed_50']['mean_time']:.3f}±{summary['fixed_50']['std_time']:.3f}\",\n",
    "        f\"{summary['fixed_100']['mean_time']:.3f}±{summary['fixed_100']['std_time']:.3f}\",\n",
    "    ],\n",
    "    'Steps': [\n",
    "        f\"{summary['adaptive']['mean_steps']:.1f}±{summary['adaptive']['std_steps']:.1f}\",\n",
    "        \"25\",\n",
    "        \"50\",\n",
    "        \"100\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization of step allocation\n",
    "print(\"\\nStep Allocation Distribution:\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.hist(df['adaptive_steps'], bins=10, edgecolor='black', color='steelblue', alpha=0.7)\n",
    "ax.axvline(df['adaptive_steps'].mean(), color='red', linestyle='--', \n",
    "           linewidth=2, label=f'Mean: {df[\"adaptive_steps\"].mean():.1f}')\n",
    "ax.set_xlabel('Number of Steps Allocated')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Adaptive Step Allocation Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStep statistics:\")\n",
    "print(f\"  Mean: {df['adaptive_steps'].mean():.1f}\")\n",
    "print(f\"  Median: {df['adaptive_steps'].median():.1f}\")\n",
    "print(f\"  Min: {df['adaptive_steps'].min():.0f}\")\n",
    "print(f\"  Max: {df['adaptive_steps'].max():.0f}\")\n",
    "print(f\"  Std: {df['adaptive_steps'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nProcessed: {len(all_results)} images\")\n",
    "print(f\"Methods: {len(methods_dict)}\")\n",
    "print(f\"Total measurements: {len(all_results) * len(methods_dict) * 6}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(f\"  - {csv_path}\")\n",
    "print(f\"  - {summary_path}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Open notebook: 4_analyze_results.ipynb\")\n",
    "print(\"  2. Generate publication-quality figures\")\n",
    "print(\"  3. Review statistical analysis\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
